{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＃实验记录，之后就不用表格了很麻烦，在这里同步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SSD\n",
    "\n",
    "ssd300×300 focal loss \n",
    "batch_size：16\n",
    "\n",
    "train_net: \"models/VGGNet/VOC0712/SSD_300x300/train.prototxt\"\n",
    "test_net: \"models/VGGNet/VOC0712/SSD_300x300/test.prototxt\"\n",
    "test_iter: 503\n",
    "test_interval: 10000\n",
    "base_lr: 0.0002\n",
    "display: 20\n",
    "max_iter: 30000\n",
    "lr_policy: \"multistep\"\n",
    "gamma: 0.1\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "snapshot: 20000\n",
    "snapshot_prefix: \"models/VGGNet/VOC0712/SSD_300x300/VGG_VOC0712_SSD_300x300\"\n",
    "solver_mode: GPU\n",
    "device_id: 0\n",
    "debug_info: false\n",
    "snapshot_after_train: true\n",
    "test_initialization: false\n",
    "average_loss: 10\n",
    "\n",
    "stepvalue: 20000\n",
    "stepvalue: 30000\n",
    "iter_size: 1\n",
    "type: \"SGD\"\n",
    "eval_type: \"detection\"\n",
    "ap_version: \"11point\"\n",
    "\n",
    "ssd focal loss训练出来效果很差　39%,是比不用提升了一些，但是效果不好(不知道是不是迭代次数不够的原因)\n",
    "\n",
    "通过观察，之前给分数较低的框，现在给出的分数很高。　0.3以上的很多，这有问题。训练到最后，loss依旧较高\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD\n",
    "\n",
    "数据未变，使用更长的迭代周期，和优化算法。\n",
    "\n",
    "train_net: \"models/VGGNet/VOC0712/SSD_300x300/train.prototxt\"\n",
    "test_net: \"models/VGGNet/VOC0712/SSD_300x300/test.prototxt\"\n",
    "test_iter: 503\n",
    "test_interval: 10000\n",
    "base_lr: 0.0002\n",
    "display: 10\n",
    "max_iter: 120000\n",
    "lr_policy: \"multistep\"\n",
    "gamma: 0.1\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "snapshot: 20000\n",
    "snapshot_prefix: \"models/VGGNet/VOC0712/SSD_300x300/VGG_VOC0712_SSD_300x300\"\n",
    "solver_mode: GPU\n",
    "device_id: 0\n",
    "debug_info: false\n",
    "snapshot_after_train: true\n",
    "test_initialization: false\n",
    "average_loss: 10\n",
    "stepvalue: 90000\n",
    "stepvalue: 110000\n",
    "iter_size: 1\n",
    "type: \"Adam\"\n",
    "eval_type: \"detection\"\n",
    "ap_version: \"11point\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "这就是简单的调参，意义不大，要看到问题未表露出来的东西。由表及里。\n",
    "预计到明天８点左右就ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rfcn\n",
    "train_net: \"/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/train_agnostic_ohem.prototxt\"\n",
    "base_lr: 0.0002\n",
    "lr_policy: \"step\"\n",
    "gamma: 0.1\n",
    "stepsize: 50000\n",
    "display: 20\n",
    "\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "#### We disable standard caffe solver snapshotting and implement our own snapshot\n",
    "#### function\n",
    "snapshot: 0\n",
    "#### We still use the snapshot prefix, though\n",
    "snapshot_prefix: \"resnet50_rfcn_ohem\"\n",
    "iter_size: 8\n",
    "#### debug_info: true\n",
    "\n",
    "\n",
    "case $DATASET in\n",
    "  pascal_voc)\n",
    "    TRAIN_IMDB=\"voc_0712_trainval\"\n",
    "    TEST_IMDB=\"voc_0712_test\"\n",
    "    PT_DIR=\"pascal_voc\"\n",
    "    ITERS=32000\n",
    "    \n",
    "    \n",
    "数据用的是张姗姗老师的改进数据\n",
    "rfcn的实验，我换用了　vis>0.6的数据。\n",
    "\n",
    "就是为了让数据更加合理，e\n",
    "\n",
    "\n",
    "train:640*1280\n",
    "test:768*1280\n",
    "map = 42%\n",
    "log average miss rate = 18.7% \n",
    "\n",
    "用这个当做baseline, 然后做。\n",
    "\n",
    "train:648*1280\n",
    "test:640*1280\n",
    "map = 28.8%\n",
    "这样就很低，怎么回事？\n",
    "log average miss rate = 17.6%\n",
    "\n",
    "\n",
    "test:960*1280\n",
    "0.29s\n",
    "log average miss rate = 17.4%\n",
    "\n",
    "test:1000*2000\n",
    "0.30s         17.6%\n",
    "fp有20000+ \n",
    "\n",
    "test:1400*2400\n",
    "0.55s\n",
    "fp只有4000+   22%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该rfcn实验，只是同上边的训练的尺度不同，其他的都一样\n",
    "\n",
    "train:960*1280\n",
    "test:960*1280\n",
    "\n",
    "log average miss rate = 20%\n",
    "\n",
    "多了很多在环境中的框，有点乱标的意思，怎么回事？\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "citypersons\n",
    "\n",
    "30%\n",
    "\n",
    "训练出来的效果特别好，没有在车上有很多分数较低的误检\n",
    "\n",
    "但是在树干上，和树冠上，还存在一定的问题\n",
    "\n",
    "将两种数据混合训练呢？\n",
    "\n",
    "我觉得培钰的top-down效果就不错\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "实验，尝试rfcn训练　caltech vis>0.6 h > 50 头部大约40%的位置，用来进行训练\n",
    "\n",
    "train_net: \"/home/user/Disk1.8T/py-R-FCN_5_29/experiments/5_28_original_head_handle/train_agnostic_ohem.prototxt\"\n",
    "base_lr: 0.0002\n",
    "lr_policy: \"step\"\n",
    "gamma: 0.1\n",
    "stepsize: 50000\n",
    "display: 20\n",
    "\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    " We disable standard caffe solver snapshotting and implement our own snapshot\n",
    " function\n",
    "snapshot: 0\n",
    " We still use the snapshot prefix, though\n",
    "snapshot_prefix: \"resnet50_rfcn_ohem\"\n",
    "iter_size: 8\n",
    " debug_info: true\n",
    "\n",
    "\n",
    "iters 32000\n",
    "\n",
    "在车身上的误检是少了很多，但是，mr=28%\n",
    "\n",
    "思路，用局部来回归整体，看效果怎么样？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试使用pspnet\n",
    "\n",
    "PSPNet 就是为了整合不同区域的context来获取全局的context 信息。\n",
    "\n",
    "中间模块是pyramid pooling module，是为了获得全局先验信息。在一个深度网络中+，感受野的尺寸大小决定有多少context 信息可以用。理论上ResNet 的感受野尺寸要比输入图像尺寸大。但是有文章指出CNN 的实际感受野尺寸要比理论尺寸小很多。之前提出的Global average pooling 对于复杂的ADE20K 数据库来说过于简单。因此，论文借鉴Spatial pyramid pooling（SPP空间金字塔池化方法）提出pyramid pooling module。\n",
    "\n",
    "第一行是用global pooling 生成的一个单独的输出。第二行将特征图等分为4 块，每块分别用global pooling 得到bin output，接下来的行以此类推。上图四行分别对应1×1, 2×2, 3×3 和6×6。\n",
    "\n",
    "为了减小维度和位置全局特征的权值，在每一行使用一个1×1 卷积层。接着我们使用双线性插值，使其和原始特征图尺寸一样大小。最后和原始特征图组合起来。\n",
    "\n",
    "\n",
    "pspnet 这样来做，只是尝试一下，但是，可能不会太好\n",
    "\n",
    "参数设置相同，就是网络结构不同"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
