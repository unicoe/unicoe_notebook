
２０１８年０５月２８日０９：２４：３４
整理实验思路：

OHEM是近年兴起的另一种筛选example的方法，它通过对loss排序，选出loss最大的example来进行训练，这样就能保证训练的区域都是hard example。这个方法有个缺陷，它把所有的easy example都去除掉了，造成easy positive example无法进一步提升训练的精度。
图1是hard positvie、hard negative、easy positive、easy negative四种example的示意图，可以直观的感受到easy negativa占了大多数。


Focal Loss通过调整loss的计算公式使单级结构达到和Faster RCNN一样的准确度，公式1是Focal Loss的计算方法。pt是不同类别的分类概率，r是个大于0的值，at是个[0，1]间的小数，r和at都是固定值，不参与训练。从表达式可以看出：
1、无论是前景类还是背景类，pt越大，权重(1-pt)r就越小。也就是说easy example可以通过权重进行抑制；
2、at用于调节positive和negative的比例，前景类别使用at时，对应的背景类别使用1-at；
3、r和at的最优值是相互影响的，所以在评估准确度时需要把两者组合起来调节。作者在论文中给出r=2、at=0.25时，ResNet-101+FPN作为backbone的结构有最优的性能。

作者：张磊_0503
链接：https://www.jianshu.com/p/204d9ad9507f
來源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

在ohem上，再进行修改，再读focal loss看，怎么回事



当前，在灯杆、树干的误检很少了，但是在车上的误检还是很多，可能的原因（１）由于标注使用的有问题，可能在ground truth中，车身就是被标记的区域；（２）使用ohem,对hard negative是都处理了，但是对于easy positive这样的样例，没有管很多，所以造成easy positive example无法进一步提升训练的精度。（ohem loss的使用，具体看）

使用现有的标注，应该是有问题的。使用张姗姗老师给的新标注，来进行训练，然后看效果。

还有就是，选取合适的数据来进行训练，通过不同的训练数据，来进行对比。

针对reasonable 测评方法，选取针对它的训练数据。

现在最好的效果LAMR=17%,使用的是两倍特征图，ohem;

如果使用focal loss，应该会效果更好。



在新的caltech标注中，遮挡的人，还是要处理一下的，有的人的身体直接就被完全遮挡了，如果拿来训练，这就是问题。

caltech_1xnew中，筛选出来遮挡较少的的行人。

需要去看原始caltech中，对于遮挡是怎么进行标记的？
然后算一个可见部分，将合适的标记晒出来。

被车身遮挡，训练还是有问题，这和处理遮挡没有关系

还有就是，怎么可以用caltech_new1x test 用来进行测评。

简单处理了一下，大于30%的可见部分，下午继续

之前用的是大于65%的reasonable部分，现在做一下大于65%的可见部分做训练，然后再做测试。

使用rfcn,自己设置最好的时候的参数，训练一个基于新数据集的模型，看效果，

然后尝试使用老杨的topdown,看能不能进行修改，结合就像论文中说的，bounding box级别的语义分割，来进行

或者看，还应该怎么搞

现在的问题是，对于hard 部分训练的是很好了，但是，对于easy的车身部分，还是给出大量的，分数较低的框，这部分就是FP(false positive),好像现在处理的还是有问题。

怎么能把这部分处理掉，这是个比较重要的问题。

不限于1x 和　10x, 使用以前自己提取的所有图片的reasonable数据集，来进行训练，得到一个模型，也是可以的。

top-down


训练时的loss曲线要画一下，看是否趋于平稳，

# 以后做实验，要把最好的caffemodel保存下来，做好记录

现在的问题是，test.prototxt和train.prototxt,配置文件，都保存下来，以后复用，也有东西。不用自己乱搞，不知道怎么搞。

搞一个最好的baseline, 然后再继续搞出来。

最好的检测器的检测效果，可视化出来看

当前实验有存在那些问题？没有想清楚，胡乱的跑实验，没有意义。

当前，fp，对于车身，有很多分数较小的框会给出，

再认真分析实验结果，看普遍存在的问题，应该从那个方向想，而不是总要依赖老师和培钰给答案。

认真看这个事情。
